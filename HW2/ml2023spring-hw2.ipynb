{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Homework 2: Phoneme Classification**\n","metadata":{"id":"OYlaRwNu7ojq"}},{"cell_type":"code","source":"!pip install wandb -qU\n\n# Log in to your W&B account\nimport wandb\nwandb.login()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-30T00:47:42.526334Z","iopub.execute_input":"2023-05-30T00:47:42.526780Z","iopub.status.idle":"2023-05-30T00:48:15.228835Z","shell.execute_reply.started":"2023-05-30T00:47:42.526693Z","shell.execute_reply":"2023-05-30T00:48:15.227761Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nallennlp 2.10.1 requires wandb<0.13.0,>=0.10.0, but you have wandb 0.15.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-05-30T00:48:15.230866Z","iopub.execute_input":"2023-05-30T00:48:15.231184Z","iopub.status.idle":"2023-05-30T00:48:15.372995Z","shell.execute_reply.started":"2023-05-30T00:48:15.231154Z","shell.execute_reply":"2023-05-30T00:48:15.371735Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"1263"},"metadata":{}}]},{"cell_type":"code","source":"# Lstm + wandb sweep\nconcat_nframes = 1              # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\ntrain_ratio = 0.75               # the ratio of data used for training, the rest will be used for validation\n\n# training parameters\nseed = 1213                        # random seed\nbatch_size = 8# batch size\nnum_epoch = 40                   # the number of training epoch\nlearning_rate = 2e-3         # learning rate\nmodel_path = './model.ckpt'     # the path where the checkpoint will be saved\n\n# model parameters\ninput_dim = 39 * concat_nframes # the input dim of the model, you should not change the value\nhidden_layers = 8               # the number of hidden layers\nhidden_dim = 256              # the hidden dim\n\nimport torch\nfrom torch.utils.data import Dataset\n\nclass LibriDataset(Dataset):\n    def __init__(self, X, y=None):\n        self.data = X\n        if y is not None:\n            # self.label = torch.LongTensor(y)\n            self.label = y\n        else:\n            self.label = None\n\n    def __getitem__(self, idx):\n        if self.label is not None:\n            return self.data[idx], self.label[idx]\n        else:\n            return self.data[idx]\n\n    def __len__(self):\n        return len(self.data)\n\n    def totalSeqLen(self):\n        # return self.data.shape[0] * self.data.shape[1]\n        x_seq_len_list = [s.shape[0] for s in self.data]\n        return sum(x_seq_len_list)\n\nimport numpy as np\nimport torch\nimport random\nimport os\nimport torch\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pack_sequence, pad_packed_sequence\nimport gc\n\n\ndef same_seeds(seed):\n    random.seed(seed) \n    np.random.seed(seed)  \n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed) \n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\n\ndef load_feat(path):\n    feat = torch.load(path)\n    return feat\n\ndef shift(x, n):\n    if n < 0:\n        left = x[0].repeat(-n, 1)\n        right = x[:n]\n    elif n > 0:\n        right = x[-1].repeat(n, 1)\n        left = x[n:]\n    else:\n        return x\n\n    return torch.cat((left, right), dim=0)\n\ndef concat_feat(x, concat_n):\n    assert concat_n % 2 == 1 # n must be odd\n    if concat_n < 2:\n        return x\n    seq_len, feature_dim = x.size(0), x.size(1)\n    x = x.repeat(1, concat_n) \n    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n    mid = (concat_n // 2)\n    for r_idx in range(1, mid+1):\n        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n\n    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n\ndef preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, random_seed=1213):\n    class_num = 41 # NOTE: pre-computed, should not need change\n\n    if split == 'train' or split == 'val':\n        mode = 'train'\n    elif split == 'test':\n        mode = 'test'\n    else:\n        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n\n    label_dict = {}\n    if mode == 'train':\n        for line in open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines():\n            line = line.strip('\\n').split(' ')\n            label_dict[line[0]] = [int(p) for p in line[1:]]\n        \n        # split training and validation data\n        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n        random.seed(random_seed)\n        random.shuffle(usage_list)\n        train_len = int(len(usage_list) * train_ratio)\n        usage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\n\n    elif mode == 'test':\n        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n\n    usage_list = [line.strip('\\n') for line in usage_list]\n    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n\n    x_tensor_list = []\n    if mode == 'train':\n        y_tensor_list = []\n\n    idx = 0\n    for i, fname in tqdm(enumerate(usage_list)):\n        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n        cur_len = len(feat)\n        feat = concat_feat(feat, concat_nframes)\n        if mode == 'train':\n          label = torch.LongTensor(label_dict[fname])\n\n        x_tensor_list.append(feat)\n        if mode == 'train':\n            y_tensor_list.append(label)\n          \n\n    # X = torch.nn.utils.rnn.pad_sequence(x_tensor_list, batch_first=True)\n    # X = torch.stack(x_tensor_list, dim=0)\n    X = x_tensor_list\n\n\n\n    if mode == 'train':\n        # y = torch.nn.utils.rnn.pad_sequence(y_tensor_list, batch_first=True)\n        # y = torch.stack(y_tensor_list, dim=0)\n        y = y_tensor_list\n\n    print(f'[INFO] {split} set')\n    if mode == 'train':\n        # print(f'[INFO] x shape: {X.shape} y shape: {y.shape}')\n        return X, y\n    else:\n        return X\n\n\ndef collate_fn(data):\n    return data\n\n\n    # data.sort(key= lambda data: len(data[0]), reverse=True) \n\n    # x_seq_list = [dataItem[0] for dataItem in data] \n    # y_seq_list = [dataItem[1] for dataItem in data]\n    # seq_len = [s.shape[0] for s in x_seq_list]\n    # x_pad_seq = pad_sequence(x_seq_list, batch_first=True) \n    # x_seq_pack = pack_padded_sequence(x_pad_seq, seq_len, batch_first=True)\n    # print(x_pad_seq.data)\n    \n\n    # print(isinstance(data, list)) \n    # features, labels = data \n\n    # # if(isinstance(data[0], tuple)){\n    # #     xD\n\n    # # }\n    \n    # # x.sort(key=lambda x: len(x), reverse=True)\n    # # seq_len = [x.size(0) for x,y in data] # 获取数据真实的长度\n    # # data = pad_sequence(data, batch_first=True)\n    # # data = pack_padded_sequence(data, seq_len, batch_first=True)\n    # return x_pad_seq, y_seq_list\n\nimport torch.nn as nn\nimport torch\nfrom torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n\nclass BasicBlock(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(BasicBlock, self).__init__()\n\n        self.block = nn.Sequential(\n            nn.Linear(input_dim, output_dim),\n            nn.ReLU(),\n        )\n\n    def forward(self, x):\n        x = self.block(x)\n        return x\n\n\nclass LstmClassifier(nn.Module):\n    def __init__(self, input_dim, output_dim=41, hidden_layers=4, hidden_dim=256, batch_size = 8, dropout = 0.4):\n        super(LstmClassifier, self).__init__()\n        self.input_dim = input_dim\n        self.batch_size = batch_size\n        self.hidden_dim = hidden_dim\n        self.hidden_layers = hidden_layers\n        self.fc =  nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU()\n        )\n        self.layer_norm = nn.LayerNorm(hidden_dim)\n        self.lstm = nn.LSTM(hidden_dim, hidden_dim, hidden_layers, dropout=0.35, batch_first = True)\n        self.bc =  nn.Sequential(\n            nn.Linear(hidden_dim, output_dim)\n        )\n\n\n    def forward(self, x, seq_lenght_list):\n        h0 = torch.randn(self.hidden_layers, x.shape[0], self.hidden_dim).to('cuda')\n        c0 = torch.randn(self.hidden_layers, x.shape[0], self.hidden_dim).to('cuda')\n        x = self.fc(x)\n        x_pad =pack_padded_sequence(x, batch_first=True, lengths=seq_lenght_list).to('cuda')\n        out, (hn, cn) = self.lstm(x_pad,(h0,c0))\n        out = pad_packed_sequence(out,batch_first=True)\n        out = self.layer_norm(out[0])\n        out = self.bc(out)\n        return out\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport math\nfrom torch.optim.lr_scheduler import LambdaLR\n\nimport random\nimport os\nimport torch\nfrom tqdm import tqdm\n\n\ndef train(config=None):\n\n    with wandb.init(config=config):\n    # Copy your config \n        config = wandb.config\n\n        same_seeds(seed)\n        device = 'cuda'\n        print(f'DEVICE: {device}')\n\n        # preprocess data\n        train_X, train_y = preprocess_data(split='train', feat_dir='/kaggle/input/ml2023spring-hw2/libriphone/feat', phone_path='/kaggle/input/ml2023spring-hw2/libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\n        val_X, val_y = preprocess_data(split='val', feat_dir='/kaggle/input/ml2023spring-hw2/libriphone/feat', phone_path='/kaggle/input/ml2023spring-hw2/libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\n\n        # get dataset\n        train_set = LibriDataset(train_X, train_y)\n        val_set = LibriDataset(val_X, val_y)\n        # remove raw feature to save memory\n        del train_X, train_y, val_X, val_y\n        gc.collect()\n\n        # get dataloader\n        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n        val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n        n_steps_per_epoch = math.ceil(len(train_set) / batch_size)\n\n        model = LstmClassifier(input_dim=input_dim, hidden_layers=config.hidden_layers, hidden_dim=hidden_dim, dropout = config.dropout).to(device)\n        #if(os.path.exists(model_path)):\n        #    model.load_state_dict(torch.load(model_path))\n        criterion = nn.CrossEntropyLoss() \n        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=config.weight_decay)\n        # 定义一个自定义函数来计算学习率\n        def lr_lambda(epoch):\n            if epoch < 5:\n                return epoch / 5\n            elif epoch < 20:\n                return 1\n            else:\n                return 0.5 * (1 + math.cos(math.pi * (epoch - 20) / (num_epoch-20)))\n\n        scheduler = LambdaLR(optimizer, lr_lambda)\n\n\n        best_acc = 0\n        example_ct = 0\n        for epoch in range(num_epoch):\n            train_acc = 0.0\n            train_loss = 0.0\n            val_acc = 0.0\n            val_loss = 0.0\n\n            # training\n            model.train() # set the model to training mode\n            for step, batch in enumerate(tqdm(train_loader)):\n                batch.sort(key= lambda batch: len(batch[0]), reverse=True) \n                x_seq_list = [dataItem[0] for dataItem in batch] \n                y_seq_list = [dataItem[1] for dataItem in batch]\n\n                x_seq_len_list = [s.shape[0] for s in x_seq_list]\n                x_pad_seq = pad_sequence(x_seq_list, batch_first=True).to(device) \n\n                optimizer.zero_grad() \n                outputs = model(x_pad_seq, x_seq_len_list) \n                result = torch.cat([outputs[i][:x_seq_len_list[i]] for i in range(outputs.size(0))], dim=0)\n                y_seq_tensor = torch.cat(y_seq_list, dim=0).to(device)\n                # print(f\"reslut shape {result.shape} , y_seq_tensor shape {y_seq_tensor.shape}\")\n\n\n                loss = criterion(result, y_seq_tensor)\n                loss.backward() \n                optimizer.step() \n\n                _, train_pred = torch.max(result, 1) # get the index of the class with the highest probability\n                # print(f\"train_pred.shape: {train_pred.shape}\")\n                # print(f\"y_seq_tensor.shape: {y_seq_tensor.shape}\")\n\n                train_acc_batch = (train_pred.detach() == y_seq_tensor.detach()).sum().item()\n                train_acc += train_acc_batch\n                train_loss += loss.item()\n\n                example_ct += len(x_pad_seq)\n                metrics = {\"train/train_loss\": loss.item(), \n                           \"train/acc\": train_acc_batch/y_seq_tensor.shape[0],\n                           \"train/epoch\": (step + 1 + (n_steps_per_epoch * epoch)) / n_steps_per_epoch, \n                           \"train/example_ct\": example_ct,\n                           \"train/learning_rate\": optimizer.state_dict()['param_groups'][0]['lr']}\n                if step % 100 == 0:\n                    print(f'Train Acc: {train_acc_batch/y_seq_tensor.shape[0]} Loss: {loss.item()}')\n            scheduler.step()\n            # validation\n            model.eval() # set the model to evaluation mode\n            with torch.no_grad():\n                for i, batch in enumerate(tqdm(val_loader)):\n                    \n                    batch.sort(key= lambda batch: len(batch[0]), reverse=True) \n                    x_seq_list = [dataItem[0] for dataItem in batch] \n                    y_seq_list = [dataItem[1] for dataItem in batch]\n\n                    x_seq_len_list = [s.shape[0] for s in x_seq_list]\n                    x_pad_seq = pad_sequence(x_seq_list, batch_first=True).to(device) \n\n                    outputs = model(x_pad_seq, x_seq_len_list)\n\n                    result = torch.cat([outputs[i][:x_seq_len_list[i]] for i in range(outputs.size(0))], dim=0)\n                    y_seq_tensor = torch.cat(y_seq_list, dim=0).to(device)\n                    #print(f\"reslut shape {result.shape} , y_seq_tensor shape {y_seq_tensor.shape}\")\n\n                    loss = criterion(result, y_seq_tensor) \n\n                    _, val_pred = torch.max(result, 1) \n                    val_acc += (val_pred.cpu() == y_seq_tensor.cpu()).sum().item() # get the index of the class with the highest probability\n                    val_loss += loss.item()\n                    \n                print(f'[{epoch+1:03d}/{num_epoch:03d}] Train Acc: {train_acc/train_set.totalSeqLen():3.5f} Loss: {train_loss/len(train_loader):3.5f} | Val Acc: {val_acc/val_set.totalSeqLen():3.5f} loss: {val_loss/len(val_loader):3.5f}')\n\n                # if the model improves, save a checkpoint at this epoch\n                val_metrics = {\"val/val_loss\": val_loss/len(val_loader), \n                \"val/val_accuracy\": val_acc/val_set.totalSeqLen()}\n                wandb.log({**metrics, **val_metrics})\n\n            if val_acc > best_acc:\n                best_acc = val_acc\n                torch.save(model.state_dict(), model_path)\n                print(f'saving model with acc {best_acc/val_set.totalSeqLen():.5f}')\n\n        wandb.finish()\nif __name__ == '__main__':\n    \n    '''\n    parameters_dict = {\n        'weight_decay': {\n          'values': [0.03, 0.04, 0.05]\n        },\n        'dropout': {\n          'values': [0.3, 0.4, 0.5]\n        },\n        \"hidden_layers\": {\n          'values': [7, 8, 9]\n        }\n    }\n\n    sweep_config = {\n        'method': 'random',\n        'metric':{\n            'name': \"val/val_accuracy\",\n            'goal': \"maximize\"\n        },\n        'parameters': parameters_dict,\n        'early_terminate':{\n            'type': \"hyperband\",\n            'min_iter': 3,\n            'eta': 1\n        }\n    }\n    parameters_dict.update({\n    'epochs': {\n        'value': num_epoch\n    },\n    'learning_rate': {\n        'value': learning_rate\n      },\n    'batch_size': {\n        'value': batch_size\n      }\n    })\n\n    import pprint\n    pprint.pprint(sweep_config)\n    sweep_id = wandb.sweep(sweep_config, project=\"lstm-for-phoneme-recognition\")\n    wandb.agent(\"liweixin2021/lstm-for-phoneme-recognition/lc1wsklf\", train, count=36)  \n\n'''\n\n","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-05-30T00:53:27.333508Z","iopub.execute_input":"2023-05-30T00:53:27.333956Z","iopub.status.idle":"2023-05-30T00:53:27.430836Z","shell.execute_reply.started":"2023-05-30T00:53:27.333904Z","shell.execute_reply":"2023-05-30T00:53:27.429484Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# BiLstm + wandb log\nconcat_nframes = 1              # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\ntrain_ratio = 0.75               # the ratio of data used for training, the rest will be used for validation\n\n# training parameters\nseed = 1213                        # random seed\nbatch_size = 8# batch size\nnum_epoch = 30                   # the number of training epoch\nlearning_rate = 2e-3         # learning rate\nmodel_path = './model.ckpt'     # the path where the checkpoint will be saved\n\n# model parameters\ninput_dim = 39 * concat_nframes # the input dim of the model, you should not change the value\nhidden_layers = 7               # the number of hidden layers\nhidden_dim = 256              # the hidden dim\ndropout = 0.35\nweight_decay = 0.05\n\nimport torch\nfrom torch.utils.data import Dataset\n\nclass LibriDataset(Dataset):\n    def __init__(self, X, y=None):\n        self.data = X\n        if y is not None:\n            # self.label = torch.LongTensor(y)\n            self.label = y\n        else:\n            self.label = None\n\n    def __getitem__(self, idx):\n        if self.label is not None:\n            return self.data[idx], self.label[idx]\n        else:\n            return self.data[idx]\n\n    def __len__(self):\n        return len(self.data)\n\n    def totalSeqLen(self):\n        # return self.data.shape[0] * self.data.shape[1]\n        x_seq_len_list = [s.shape[0] for s in self.data]\n        return sum(x_seq_len_list)\n\nimport numpy as np\nimport torch\nimport random\nimport os\nimport torch\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pack_sequence, pad_packed_sequence\nimport gc\n\n\ndef same_seeds(seed):\n    random.seed(seed) \n    np.random.seed(seed)  \n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed) \n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\n\ndef load_feat(path):\n    feat = torch.load(path)\n    return feat\n\ndef shift(x, n):\n    if n < 0:\n        left = x[0].repeat(-n, 1)\n        right = x[:n]\n    elif n > 0:\n        right = x[-1].repeat(n, 1)\n        left = x[n:]\n    else:\n        return x\n\n    return torch.cat((left, right), dim=0)\n\ndef concat_feat(x, concat_n):\n    assert concat_n % 2 == 1 # n must be odd\n    if concat_n < 2:\n        return x\n    seq_len, feature_dim = x.size(0), x.size(1)\n    x = x.repeat(1, concat_n) \n    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n    mid = (concat_n // 2)\n    for r_idx in range(1, mid+1):\n        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n\n    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n\ndef preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, random_seed=1213):\n    class_num = 41 # NOTE: pre-computed, should not need change\n\n    if split == 'train' or split == 'val':\n        mode = 'train'\n    elif split == 'test':\n        mode = 'test'\n    else:\n        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n\n    label_dict = {}\n    if mode == 'train':\n        for line in open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines():\n            line = line.strip('\\n').split(' ')\n            label_dict[line[0]] = [int(p) for p in line[1:]]\n        \n        # split training and validation data\n        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n        random.seed(random_seed)\n        random.shuffle(usage_list)\n        train_len = int(len(usage_list) * train_ratio)\n        usage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\n\n    elif mode == 'test':\n        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n\n    usage_list = [line.strip('\\n') for line in usage_list]\n    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n\n    x_tensor_list = []\n    if mode == 'train':\n        y_tensor_list = []\n\n    idx = 0\n    for i, fname in tqdm(enumerate(usage_list)):\n        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n        cur_len = len(feat)\n        feat = concat_feat(feat, concat_nframes)\n        if mode == 'train':\n          label = torch.LongTensor(label_dict[fname])\n\n        x_tensor_list.append(feat)\n        if mode == 'train':\n            y_tensor_list.append(label)\n          \n\n    # X = torch.nn.utils.rnn.pad_sequence(x_tensor_list, batch_first=True)\n    # X = torch.stack(x_tensor_list, dim=0)\n    X = x_tensor_list\n\n\n\n    if mode == 'train':\n        # y = torch.nn.utils.rnn.pad_sequence(y_tensor_list, batch_first=True)\n        # y = torch.stack(y_tensor_list, dim=0)\n        y = y_tensor_list\n\n    print(f'[INFO] {split} set')\n    if mode == 'train':\n        # print(f'[INFO] x shape: {X.shape} y shape: {y.shape}')\n        return X, y\n    else:\n        return X\n\n\ndef collate_fn(data):\n    return data\n\n\nimport torch.nn as nn\nimport torch\nfrom torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n\nclass BasicBlock(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(BasicBlock, self).__init__()\n\n        self.block = nn.Sequential(\n            nn.Linear(input_dim, output_dim),\n            nn.ReLU(),\n        )\n\n    def forward(self, x):\n        x = self.block(x)\n        return x\n\n\nclass LstmClassifier(nn.Module):\n    def __init__(self, input_dim, output_dim=41, hidden_layers=4, hidden_dim=256, batch_size = 8):\n        super(LstmClassifier, self).__init__()\n        self.input_dim = input_dim\n        self.batch_size = batch_size\n        self.hidden_dim = hidden_dim\n        self.hidden_layers = hidden_layers\n        self.fc =  nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout (dropout)\n        )\n        self.layer_norm = nn.LayerNorm(hidden_dim * 2 )\n        self.lstm = nn.LSTM(hidden_dim, hidden_dim, hidden_layers, dropout=dropout, bidirectional = True, batch_first = True)\n        self.bc =  nn.Sequential(\n            nn.Dropout (dropout),\n            nn.Linear(hidden_dim *2, output_dim)\n        )\n\n\n    def forward(self, x, seq_lenght_list):\n        h0 = torch.randn(self.hidden_layers*2, x.shape[0], self.hidden_dim).to('cuda')\n        c0 = torch.randn(self.hidden_layers*2, x.shape[0], self.hidden_dim).to('cuda')\n        x = self.fc(x)\n        x_pad =pack_padded_sequence(x, batch_first=True, lengths=seq_lenght_list).to('cuda')\n        out, (hn, cn) = self.lstm(x_pad,(h0,c0))\n        out = pad_packed_sequence(out,batch_first=True)\n        out = self.layer_norm(out[0])\n        out = self.bc(out)\n        return out\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport math\nfrom torch.optim.lr_scheduler import LambdaLR\n\nimport random\nimport os\nimport torch\nfrom tqdm import tqdm\n\n\n\ndef train():\n    wandb.init(\n        project=\"lstm-for-phoneme-recognition\",\n        config={\n            \"epochs\": num_epoch,\n            \"batch_size\": batch_size,\n            \"lr\": learning_rate,\n            \"dropout\": dropout,\n            \"weight_decay\": weight_decay\n            }\n    )\n    # Copy your config \n    config = wandb.config\n    same_seeds(seed)\n    device = 'cuda'\n    print(f'DEVICE: {device}')\n\n    # preprocess data\n    train_X, train_y = preprocess_data(split='train', feat_dir='/kaggle/input/ml2023spring-hw2/libriphone/feat', phone_path='/kaggle/input/ml2023spring-hw2/libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\n    val_X, val_y = preprocess_data(split='val', feat_dir='/kaggle/input/ml2023spring-hw2/libriphone/feat', phone_path='/kaggle/input/ml2023spring-hw2/libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\n\n    # get dataset\n    train_set = LibriDataset(train_X, train_y)\n    val_set = LibriDataset(val_X, val_y)\n    # remove raw feature to save memory\n    del train_X, train_y, val_X, val_y\n    gc.collect()\n\n    # get dataloader\n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n    n_steps_per_epoch = math.ceil(len(train_set) / batch_size)\n\n    model = LstmClassifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n    #if(os.path.exists(model_path)):\n    #    model.load_state_dict(torch.load(model_path))\n    criterion = nn.CrossEntropyLoss() \n    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    # 定义一个自定义函数来计算学习率\n    def lr_lambda(epoch):\n        if epoch < 5:\n            return epoch / 5\n        elif epoch < 20:\n            return 1\n        else:\n            return 0.5 * (1 + math.cos(math.pi * (epoch - 20) / (num_epoch-20)))\n\n    scheduler = LambdaLR(optimizer, lr_lambda)\n\n\n    best_acc = 0\n    example_ct = 0\n    for epoch in range(num_epoch):\n        print(optimizer.state_dict()['param_groups'][0]['lr'])\n        train_acc = 0.0\n        train_loss = 0.0\n        val_acc = 0.0\n        val_loss = 0.0\n\n        # training\n        model.train() # set the model to training mode\n        for step, batch in enumerate(tqdm(train_loader)):\n            batch.sort(key= lambda batch: len(batch[0]), reverse=True) \n            x_seq_list = [dataItem[0] for dataItem in batch] \n            y_seq_list = [dataItem[1] for dataItem in batch]\n\n            x_seq_len_list = [s.shape[0] for s in x_seq_list]\n            x_pad_seq = pad_sequence(x_seq_list, batch_first=True).to(device) \n\n            optimizer.zero_grad() \n            outputs = model(x_pad_seq, x_seq_len_list) \n            result = torch.cat([outputs[i][:x_seq_len_list[i]] for i in range(outputs.size(0))], dim=0)\n            y_seq_tensor = torch.cat(y_seq_list, dim=0).to(device)\n            # print(f\"reslut shape {result.shape} , y_seq_tensor shape {y_seq_tensor.shape}\")\n\n\n            loss = criterion(result, y_seq_tensor)\n            loss.backward() \n            optimizer.step() \n\n            _, train_pred = torch.max(result, 1) # get the index of the class with the highest probability\n            # print(f\"train_pred.shape: {train_pred.shape}\")\n            # print(f\"y_seq_tensor.shape: {y_seq_tensor.shape}\")\n\n            train_acc_batch = (train_pred.detach() == y_seq_tensor.detach()).sum().item()\n            train_acc += train_acc_batch\n            train_loss += loss.item()\n\n            example_ct += len(x_pad_seq)\n            metrics = {\"train/train_loss\": loss.item(), \n                       \"train/acc\": train_acc_batch/y_seq_tensor.shape[0],\n                       \"train/epoch\": (step + 1 + (n_steps_per_epoch * epoch)) / n_steps_per_epoch, \n                       \"train/example_ct\": example_ct,\n                        \"train/lr\": optimizer.state_dict()['param_groups'][0]['lr']\n                      }\n            if step % 100 == 0:\n                print(f'Train Acc: {train_acc_batch/y_seq_tensor.shape[0]} Loss: {loss.item()}')\n        scheduler.step()\n        # validation\n        model.eval() # set the model to evaluation mode\n        with torch.no_grad():\n            for i, batch in enumerate(tqdm(val_loader)):\n                \n                batch.sort(key= lambda batch: len(batch[0]), reverse=True) \n                x_seq_list = [dataItem[0] for dataItem in batch] \n                y_seq_list = [dataItem[1] for dataItem in batch]\n\n                x_seq_len_list = [s.shape[0] for s in x_seq_list]\n                x_pad_seq = pad_sequence(x_seq_list, batch_first=True).to(device) \n\n                outputs = model(x_pad_seq, x_seq_len_list)\n\n                result = torch.cat([outputs[i][:x_seq_len_list[i]] for i in range(outputs.size(0))], dim=0)\n                y_seq_tensor = torch.cat(y_seq_list, dim=0).to(device)\n                #print(f\"reslut shape {result.shape} , y_seq_tensor shape {y_seq_tensor.shape}\")\n\n                loss = criterion(result, y_seq_tensor) \n\n                _, val_pred = torch.max(result, 1) \n                val_acc += (val_pred.cpu() == y_seq_tensor.cpu()).sum().item() # get the index of the class with the highest probability\n                val_loss += loss.item()\n                \n            print(f'[{epoch+1:03d}/{num_epoch:03d}] Train Acc: {train_acc/train_set.totalSeqLen():3.5f} Loss: {train_loss/len(train_loader):3.5f} | Val Acc: {val_acc/val_set.totalSeqLen():3.5f} loss: {val_loss/len(val_loader):3.5f}')\n\n            # if the model improves, save a checkpoint at this epoch\n            val_metrics = {\"val/val_loss\": val_loss/len(val_loader), \n            \"val/val_accuracy\": val_acc/val_set.totalSeqLen()}\n            wandb.log({**metrics, **val_metrics})\n\n        if val_acc > best_acc:\n            best_acc = val_acc\n            torch.save(model.state_dict(), model_path)\n            print(f'saving model with acc {best_acc/val_set.totalSeqLen():.5f}')\n\n    wandb.finish()\nif __name__ == '__main__':\n    train()\n\n    \n  ","metadata":{"execution":{"iopub.status.busy":"2023-05-30T00:48:23.538927Z","iopub.execute_input":"2023-05-30T00:48:23.539332Z","iopub.status.idle":"2023-05-30T00:52:29.694285Z","shell.execute_reply.started":"2023-05-30T00:48:23.539296Z","shell.execute_reply":"2023-05-30T00:52:29.692445Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mliweixin2021\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230530_004825-fwndwwgv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/liweixin2021/lstm-for-phoneme-recognition/runs/fwndwwgv' target=\"_blank\">lyric-frog-61</a></strong> to <a href='https://wandb.ai/liweixin2021/lstm-for-phoneme-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/liweixin2021/lstm-for-phoneme-recognition' target=\"_blank\">https://wandb.ai/liweixin2021/lstm-for-phoneme-recognition</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/liweixin2021/lstm-for-phoneme-recognition/runs/fwndwwgv' target=\"_blank\">https://wandb.ai/liweixin2021/lstm-for-phoneme-recognition/runs/fwndwwgv</a>"},"metadata":{}},{"name":"stdout","text":"DEVICE: cuda\n[Dataset] - # phone classes: 41, number of utterances for train: 2571\n","output_type":"stream"},{"name":"stderr","text":"2571it [00:13, 187.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"[INFO] train set\n[Dataset] - # phone classes: 41, number of utterances for val: 858\n","output_type":"stream"},{"name":"stderr","text":"858it [00:04, 181.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"[INFO] val set\n0.0\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 1/322 [00:04<23:49,  4.45s/it]","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.042 Loss: 3.851104974746704\n","output_type":"stream"},{"name":"stderr","text":" 31%|███▏      | 101/322 [01:20<02:56,  1.25it/s]","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.041337590320954465 Loss: 3.8776588439941406\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 201/322 [02:33<01:25,  1.42it/s]","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.04041237113402062 Loss: 3.847459316253662\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 245/322 [03:07<00:58,  1.31it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/4192063320.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/4192063320.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_seq_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"  \nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\nimport random\nimport os\nimport torch\nfrom tqdm import tqdm\n\n\nfrom torchsummary import summary\n# load data\ntest_X = preprocess_data(split='test', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes)\ntest_set = LibriDataset(test_X, None)\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False,collate_fn=collate_fn)\nmodel = LstmClassifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(\"cuda\")\n#model = LstmClassifier(input_dim=input_dim).to(device)\nmodel.load_state_dict(torch.load(model_path))\n\npred = np.array([], dtype=np.int32)\n\nmodel.eval()\nwith torch.no_grad():\n    for i, batch in enumerate(tqdm(test_loader)):\n        x_seq_list = batch \n\n        seq_len = [s.shape[0] for s in x_seq_list]\n        # print(sum(seq_len))\n        x_pad_seq = pad_sequence(x_seq_list, batch_first=True).to('cuda') \n\n\n        outputs = model(x_pad_seq)\n        \n        result = torch.cat([outputs[i][:seq_len[i]] for i in range(outputs.size(0))], dim=0)\n\n        # for i in range(len(outputs)):\n        #     print(outputs[i].shape)\n        #     outputs[i] = outputs[i][:seq_len[i]]\n        # outputs = torch.reshape(outputs, (outputs.shape[0] * outputs.shape[1] , outputs.shape[2]))\n\n        # print(outputs.shape)\n        \n\n        _, test_pred = torch.max(result, 1) # get the index of the class with the highest probability\n        print(test_pred.shape)\n        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)\n\n\nwith open('prediction.csv', 'w') as f:\n    f.write('Id,Class\\n')\n    for i, y in enumerate(pred):\n        f.write('{},{}\\n'.format(i, y))","metadata":{"execution":{"iopub.status.busy":"2023-05-28T05:47:11.812028Z","iopub.status.idle":"2023-05-28T05:47:11.813352Z","shell.execute_reply.started":"2023-05-28T05:47:11.813004Z","shell.execute_reply":"2023-05-28T05:47:11.813036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-05-28T05:47:11.819444Z","iopub.status.idle":"2023-05-28T05:47:11.820471Z","shell.execute_reply.started":"2023-05-28T05:47:11.820186Z","shell.execute_reply":"2023-05-28T05:47:11.820211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/accelerate","metadata":{"execution":{"iopub.status.busy":"2023-05-28T05:47:11.821630Z","iopub.status.idle":"2023-05-28T05:47:11.822609Z","shell.execute_reply.started":"2023-05-28T05:47:11.822290Z","shell.execute_reply":"2023-05-28T05:47:11.822327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import os\n#from accelerate.utils import write_basic_config\n#write_basic_config() # Write a config file\n#os._exit(0)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T05:47:11.824165Z","iopub.status.idle":"2023-05-28T05:47:11.825019Z","shell.execute_reply.started":"2023-05-28T05:47:11.824758Z","shell.execute_reply":"2023-05-28T05:47:11.824785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport torch.nn as nn\n#from torch.optim.lr_scheduler import LambdaLR\n#import random\nfrom torch.utils.data import DataLoader\n\nimport numpy as np\n#import math\nimport os\nfrom tqdm import tqdm\nimport datetime\nimport gc\n\n# Accelerate parts\nfrom accelerate import Accelerator, notebook_launcher # main interface, distributed launcher\nfrom accelerate.utils import set_seed # reproducability across devices","metadata":{"execution":{"iopub.status.busy":"2023-05-28T05:47:11.826437Z","iopub.status.idle":"2023-05-28T05:47:11.827514Z","shell.execute_reply.started":"2023-05-28T05:47:11.827181Z","shell.execute_reply":"2023-05-28T05:47:11.827217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!accelerate env","metadata":{"execution":{"iopub.status.busy":"2023-05-28T05:47:11.828969Z","iopub.status.idle":"2023-05-28T05:47:11.829815Z","shell.execute_reply.started":"2023-05-28T05:47:11.829537Z","shell.execute_reply":"2023-05-28T05:47:11.829561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!accelerate config","metadata":{"execution":{"iopub.status.busy":"2023-05-28T05:47:11.831217Z","iopub.status.idle":"2023-05-28T05:47:11.832075Z","shell.execute_reply.started":"2023-05-28T05:47:11.831808Z","shell.execute_reply":"2023-05-28T05:47:11.831833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LibriDataset(Dataset):\n    def __init__(self, X, y=None):\n        self.data = X\n        if y is not None:\n            # self.label = torch.LongTensor(y)\n            self.label = y\n        else:\n            self.label = None\n\n    def __getitem__(self, idx):\n        if self.label is not None:\n            return self.data[idx], self.label[idx]\n        else:\n            return self.data[idx]\n\n    def __len__(self):\n        return len(self.data)\n\n    def totalSeqLen(self):\n        x_seq_len_list = [s.shape[0] for s in self.data]\n        return sum(x_seq_len_list)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T05:47:11.833702Z","iopub.status.idle":"2023-05-28T05:47:11.834550Z","shell.execute_reply.started":"2023-05-28T05:47:11.834284Z","shell.execute_reply":"2023-05-28T05:47:11.834316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef load_feat(path):\n    import torch\n    feat = torch.load(path)\n    return feat\n\ndef preprocess_data(split, feat_dir, phone_path, train_ratio=0.8, random_seed=1213):\n\n    if split == 'train' or split == 'val':\n        mode = 'train'\n    elif split == 'test':\n        mode = 'test'\n    else:\n        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n\n    label_dict = {}\n    if mode == 'train':\n        for line in open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines():\n            line = line.strip('\\n').split(' ')\n            label_dict[line[0]] = [int(p) for p in line[1:]]\n        \n        # split training and validation data\n        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n        train_len = int(len(usage_list) * train_ratio)\n        usage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\n\n    elif mode == 'test':\n        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n\n    usage_list = [line.strip('\\n') for line in usage_list]\n\n    x_tensor_list = []\n    if mode == 'train':\n        y_tensor_list = []\n\n    idx = 0\n    for i, fname in enumerate(usage_list):\n        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n        cur_len = len(feat)\n        if mode == 'train':\n            label = label_dict[fname]\n\n        x_tensor_list.append(feat)\n        if mode == 'train':\n            y_tensor_list.append(label)\n          \n\n    X = x_tensor_list\n\n\n\n    if mode == 'train':\n        y = y_tensor_list\n\n    if mode == 'train':\n        return X, y\n    else:\n        return X\n\n\ndef collate_fn(data):\n    return data\n\n\n    # data.sort(key= lambda data: len(data[0]), reverse=True) \n\n    # x_seq_list = [dataItem[0] for dataItem in data] \n    # y_seq_list = [dataItem[1] for dataItem in data]\n    # seq_len = [s.shape[0] for s in x_seq_list]\n    # x_pad_seq = pad_sequence(x_seq_list, batch_first=True) \n    # x_seq_pack = pack_padded_sequence(x_pad_seq, seq_len, batch_first=True)\n    # print(x_pad_seq.data)\n    \n\n    # print(isinstance(data, list)) \n    # features, labels = data \n\n    # # if(isinstance(data[0], tuple)){\n    # #     xD\n\n    # # }\n    \n    # # x.sort(key=lambda x: len(x), reverse=True)\n    # # seq_len = [x.size(0) for x,y in data] # 获取数据真实的长度\n    # # data = pad_sequence(data, batch_first=True)\n    # # data = pack_padded_sequence(data, seq_len, batch_first=True)\n    # return x_pad_seq, y_seq_list ","metadata":{"execution":{"iopub.status.busy":"2023-05-28T05:47:11.836061Z","iopub.status.idle":"2023-05-28T05:47:11.836708Z","shell.execute_reply.started":"2023-05-28T05:47:11.836448Z","shell.execute_reply":"2023-05-28T05:47:11.836474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#print(torch.cuda.is_initialized())","metadata":{"execution":{"iopub.status.busy":"2023-05-28T05:47:11.838422Z","iopub.status.idle":"2023-05-28T05:47:11.839263Z","shell.execute_reply.started":"2023-05-28T05:47:11.839001Z","shell.execute_reply":"2023-05-28T05:47:11.839026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass BasicBlock(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(BasicBlock, self).__init__()\n\n        self.block = nn.Sequential(\n            nn.Linear(input_dim, output_dim),\n            nn.ReLU(),\n        )\n\n    def forward(self, x):\n        x = self.block(x)\n        return x\n\n\nclass LstmClassifier(nn.Module):\n    def __init__(self, input_dim, output_dim=41, hidden_layers=4, hidden_dim=256, batch_size = 8):\n        super(LstmClassifier, self).__init__()\n        self.input_dim = input_dim\n        self.batch_size = batch_size\n        self.hidden_dim = hidden_dim\n        self.hidden_layers = hidden_layers\n        self.fc =  nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU()\n        )\n        self.layer_norm = nn.LayerNorm(hidden_dim)\n        self.bc =  nn.Sequential(\n            nn.Linear(hidden_dim, output_dim)\n        )\n\n\n\n    def forward(self, x, seq_lenght_list , device):\n        #h0 = torch.randn(self.hidden_layers, x.shape[0], self.hidden_dim).to(device)\n        #c0 = torch.randn(self.hidden_layers, x.shape[0], self.hidden_dim).to(device)\n        x = self.fc(x)\n        out = self.layer_norm(out[0])\n        out = self.bc(out)\n        return out\n","metadata":{"execution":{"iopub.status.busy":"2023-05-28T05:47:11.840707Z","iopub.status.idle":"2023-05-28T05:47:11.841548Z","shell.execute_reply.started":"2023-05-28T05:47:11.841282Z","shell.execute_reply":"2023-05-28T05:47:11.841313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#print(torch.cuda.is_initialized())","metadata":{"execution":{"iopub.status.busy":"2023-05-28T05:47:11.843151Z","iopub.status.idle":"2023-05-28T05:47:11.844031Z","shell.execute_reply.started":"2023-05-28T05:47:11.843776Z","shell.execute_reply":"2023-05-28T05:47:11.843802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\ndef training_loop(\n        mixed_precision:str=\"no\",     \n        train_ratio = 0.75, \n        seed = 1213, \n        batch_size = 8, \n        input_dim = 39,\n        hidden_layers = 7,\n        hidden_dim = 256 ):\n    # initialize accelerator and auto move data/model to accelerator.device\n\n    set_seed(42)\n    accelerator = Accelerator(mixed_precision=mixed_precision)\n    \n  \n\n\n    # preprocess data\n    train_X, train_y = preprocess_data(split='train', feat_dir='/kaggle/input/ml2023spring-hw2/libriphone/feat', phone_path='/kaggle/input/ml2023spring-hw2/libriphone', train_ratio=train_ratio, random_seed=seed)\n    val_X, val_y = preprocess_data(split='val', feat_dir='/kaggle/input/ml2023spring-hw2/libriphone/feat', phone_path='/kaggle/input/ml2023spring-hw2/libriphone',  train_ratio=train_ratio, random_seed=seed)\n\n    # get dataset\n    train_set = LibriDataset(train_X, train_y)\n    val_set = LibriDataset(val_X, val_y)\n    # remove raw feature to save memory\n    del train_X, train_y, val_X, val_y\n    gc.collect()\n\n\n    \n #======================================================================\n\n    # get dataloader\n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n    model = LstmClassifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim)\n    \n    #if(os.path.exists(model_path)):       \n    #    model.load_state_dict(torch.load(model_path))\n    criterion = nn.CrossEntropyLoss() \n    optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n    # 定义一个自定义函数来计算学习率\n    #def lr_lambda(epoch):\n    #    if epoch < 10:\n    #        return epoch / 10\n    #    else:\n    #        return 0.5 * (1 + math.cos(math.pi * (epoch - 10) / 20))\n    #scheduler = LambdaLR(optimizer, lr_lambda)\n    \n\n    \n    model, optimizer, train_loader, val_loader = accelerator.prepare(\n        model, optimizer, train_loader, val_loader)\n    \n    accelerator.print(f'device {str(accelerator.device)} is used!')\n    \n    accelerator.print(mixed_precision, train_ratio, seed, batch_size,learning_rate, model_path , input_dim, hidden_layers ,hidden_dim)\n    same_seeds(seed)\n    #======================================================================\n\n    best_acc = 0\n    for epoch in range(40):\n        accelerator.print(optimizer.state_dict()['param_groups'][0]['lr'])\n        train_acc = 0.0\n        train_loss = 0.0\n        val_acc = 0.0\n        val_loss = 0.0\n\n        # training\n        model.train() # set the model to training mode\n        for i, batch in enumerate(tqdm(train_loader)):\n            batch.sort(key= lambda batch: len(batch[0]), reverse=True) \n            x_seq_list = [dataItem[0] for dataItem in batch] \n            y_seq_list = [dataItem[1] for dataItem in batch]\n\n            x_seq_len_list = [s.shape[0] for s in x_seq_list]\n            x_pad_seq = pad_sequence(x_seq_list, batch_first=True) \n\n            optimizer.zero_grad() \n            outputs = model(x_pad_seq, x_seq_len_list, device = accelerator.device) \n            result = torch.cat([outputs[i][:x_seq_len_list[i]] for i in range(outputs.size(0))], dim=0)\n            y_seq_tensor = torch.cat(y_seq_list, dim=0)\n            # print(f\"reslut shape {result.shape} , y_seq_tensor shape {y_seq_tensor.shape}\")\n\n\n            loss = criterion(result, y_seq_tensor)\n            \n            #======================================================================\n            #attention here! \n            #loss.backward() \n            accelerator.backward(loss) #loss.backward()\n            #======================================================================\n\n\n            _, train_pred = torch.max(result, 1) # get the index of the class with the highest probability\n            # print(f\"train_pred.shape: {train_pred.shape}\")\n            # print(f\"y_seq_tensor.shape: {y_seq_tensor.shape}\")\n\n            train_acc_batch = (train_pred.detach() == y_seq_tensor.detach()).sum().item()\n            train_acc += train_acc_batch\n            train_loss += loss.item()\n            if i % 100 == 0:\n                accelerator.print(f'Train Acc: {train_acc_batch/y_seq_tensor.shape[0]} Loss: {loss.item()}')\n        # validation\n        model.eval() # set the model to evaluation mode\n        with torch.no_grad():\n            for i, batch in enumerate(tqdm(val_loader)):\n                \n                batch.sort(key= lambda batch: len(batch[0]), reverse=True) \n                x_seq_list = [dataItem[0] for dataItem in batch] \n                y_seq_list = [dataItem[1] for dataItem in batch]\n\n                x_seq_len_list = [s.shape[0] for s in x_seq_list]\n                x_pad_seq = pad_sequence(x_seq_list, batch_first=True)\n\n                outputs = model(x_pad_seq, x_seq_len_list, device = accelerator.device)\n\n                result = torch.cat([outputs[i][:x_seq_len_list[i]] for i in range(outputs.size(0))], dim=0)\n                y_seq_tensor = torch.cat(y_seq_list, dim=0)\n       \n                loss = criterion(result, y_seq_tensor) \n\n                _, val_pred = torch.max(result, 1) \n            \n                #======================================================================\n                #gather data from multi-gpus (used when in ddp mode)\n                val_pred = accelerator.gather(val_pred)\n                y_seq_tensor = accelerator.gather(y_seq_tensor)\n                #======================================================================\n\n    \n                val_acc += (val_pred.cpu() == y_seq_tensor.cpu()).sum().item() # get the index of the class with the highest probability\n                val_loss += loss.item()\n                \n            accelerator.print(f'[{epoch+1:03d}/{num_epoch:03d}] Train Acc: {train_acc/train_set.totalSeqLen():3.5f} Loss: {train_loss/len(train_loader):3.5f} | Val Acc: {val_acc/val_set.totalSeqLen():3.5f} loss: {val_loss/len(val_loader):3.5f}')\n\n        #======================================================================\n        #print logs and save ckpt  \n        model_path=\"model.ckpt\"\n        accelerator.wait_for_everyone()\n        nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        accelerator.print(f\"epoch【{epoch}】@{nowtime} --> val_acc= {100 * val_acc:.2f}%\")\n        unwrapped_net = accelerator.unwrap_model(model)\n        accelerator.save(unwrapped_net.state_dict(),model_path+\"_\"+str(epoch))\n        #======================================================================\n\n        '''\n        # if the model improves, save a checkpoint at this epoch\n        if val_acc > best_acc:\n            best_acc = val_acc\n            torch.save(model.state_dict(), model_path)\n            print(f'saving model with acc {best_acc/val_set.totalSeqLen():.5f}')\n        '''","metadata":{"execution":{"iopub.status.busy":"2023-05-28T05:47:11.845606Z","iopub.status.idle":"2023-05-28T05:47:11.846264Z","shell.execute_reply.started":"2023-05-28T05:47:11.846009Z","shell.execute_reply":"2023-05-28T05:47:11.846034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import torch\n#print(torch.cuda.is_initialized())","metadata":{"execution":{"iopub.status.busy":"2023-05-28T05:47:11.847858Z","iopub.status.idle":"2023-05-28T05:47:11.848773Z","shell.execute_reply.started":"2023-05-28T05:47:11.848500Z","shell.execute_reply":"2023-05-28T05:47:11.848525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"notebook_launcher(training_loop, (\"no\",  0.75, 1213, 8, 39, 7,256 ) ,num_processes=2)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T05:47:11.850167Z","iopub.status.idle":"2023-05-28T05:47:11.851010Z","shell.execute_reply.started":"2023-05-28T05:47:11.850739Z","shell.execute_reply":"2023-05-28T05:47:11.850777Z"},"trusted":true},"execution_count":null,"outputs":[]}]}