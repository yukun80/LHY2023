{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Homework 1: COVID-19 Cases Prediction (Regression)**","metadata":{"id":"guE34D3Fj2R9"}},{"cell_type":"markdown","source":"Objectives:\n* Solve a regression problem with deep neural networks (DNN).\n* Understand basic DNN training tips.\n* Familiarize yourself with PyTorch.\n\nIf you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com","metadata":{"id":"V57zhcTp1Xxb"}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"GUATI4ONArv_","execution":{"iopub.status.busy":"2023-06-15T16:04:20.915559Z","iopub.execute_input":"2023-06-15T16:04:20.915975Z","iopub.status.idle":"2023-06-15T16:04:22.048746Z","shell.execute_reply.started":"2023-06-15T16:04:20.915941Z","shell.execute_reply":"2023-06-15T16:04:22.047323Z"},"trusted":true},"execution_count":113,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nThu Jun 15 16:04:21 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   39C    P0    34W / 250W |    821MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Download data\nIf the Google Drive links below do not work, you can use the dropbox link below or download data from [Kaggle](https://www.kaggle.com/t/a339b77fa5214978bfb8dde62d3151fe), and upload data manually to the workspace.","metadata":{"id":"Tm2aXcb-j9Fc"}},{"cell_type":"code","source":"# google drive link\n# !pip install gdown\n# !gdown --id '1BjXalPZxq9mybPKNjF3h5L3NcF7XKTS-' --output covid_train.csv\n# !gdown --id '1B55t74Jg2E5FCsKCsUEkPKIuqaY7UIi1' --output covid_test.csv\n\n# dropbox link\n!wget -O covid_train.csv https://www.dropbox.com/s/lmy1riadzoy0ahw/covid.train.csv?dl=0\n!wget -O covid_test.csv https://www.dropbox.com/s/zalbw42lu4nmhr2/covid.test.csv?dl=0","metadata":{"id":"YPmfl-awlKZA","execution":{"iopub.status.busy":"2023-06-15T16:04:22.051114Z","iopub.execute_input":"2023-06-15T16:04:22.051501Z","iopub.status.idle":"2023-06-15T16:04:25.997783Z","shell.execute_reply.started":"2023-06-15T16:04:22.051456Z","shell.execute_reply":"2023-06-15T16:04:25.996263Z"},"trusted":true},"execution_count":114,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n--2023-06-15 16:04:23--  https://www.dropbox.com/s/lmy1riadzoy0ahw/covid.train.csv?dl=0\nResolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6021:18::a27d:4112\nConnecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: /s/raw/lmy1riadzoy0ahw/covid.train.csv [following]\n--2023-06-15 16:04:23--  https://www.dropbox.com/s/raw/lmy1riadzoy0ahw/covid.train.csv\nReusing existing connection to www.dropbox.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://ucdea96f6afac435790bcb1cb35f.dl.dropboxusercontent.com/cd/0/inline/B-CWiid1e2BgybpB9miiM1d0jve0_R0Fkz6E3xlZB4FkOKkWC_n-rm4xHOJo9An5QOV93zukyz5mqUXxiqB5fFW0SZ4nSP1lyX81dmPCl-JMYuZU1XkeC2DhS5cO8_0bOHoLEsm4CAuIlstS3hrjLwat7lWZIZa7UiQSdY5nW-yjnA/file# [following]\n--2023-06-15 16:04:23--  https://ucdea96f6afac435790bcb1cb35f.dl.dropboxusercontent.com/cd/0/inline/B-CWiid1e2BgybpB9miiM1d0jve0_R0Fkz6E3xlZB4FkOKkWC_n-rm4xHOJo9An5QOV93zukyz5mqUXxiqB5fFW0SZ4nSP1lyX81dmPCl-JMYuZU1XkeC2DhS5cO8_0bOHoLEsm4CAuIlstS3hrjLwat7lWZIZa7UiQSdY5nW-yjnA/file\nResolving ucdea96f6afac435790bcb1cb35f.dl.dropboxusercontent.com (ucdea96f6afac435790bcb1cb35f.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6021:15::a27d:410f\nConnecting to ucdea96f6afac435790bcb1cb35f.dl.dropboxusercontent.com (ucdea96f6afac435790bcb1cb35f.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2162766 (2.1M) [text/plain]\nSaving to: ‘covid_train.csv’\n\ncovid_train.csv     100%[===================>]   2.06M  --.-KB/s    in 0.1s    \n\n2023-06-15 16:04:24 (21.7 MB/s) - ‘covid_train.csv’ saved [2162766/2162766]\n\n/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n--2023-06-15 16:04:25--  https://www.dropbox.com/s/zalbw42lu4nmhr2/covid.test.csv?dl=0\nResolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6021:18::a27d:4112\nConnecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: /s/raw/zalbw42lu4nmhr2/covid.test.csv [following]\n--2023-06-15 16:04:25--  https://www.dropbox.com/s/raw/zalbw42lu4nmhr2/covid.test.csv\nReusing existing connection to www.dropbox.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://uca736102615a2cb98cdf01cbff1.dl.dropboxusercontent.com/cd/0/inline/B-BYM2e5QA_tDkOd2m6yTeezEjPnJUsKXmzqh_-xg5bKKyRoYcLPhc12oLcNllbqYk93frao2PZoMx2sORUx_4pcYz9RwEXr81imuWXf7SNyh9SDQpMFBFidAngH-2aCSHCiL8Xf-KPw3QMC_ghENbDPKI9eGmwajWricNmOcM86Og/file# [following]\n--2023-06-15 16:04:25--  https://uca736102615a2cb98cdf01cbff1.dl.dropboxusercontent.com/cd/0/inline/B-BYM2e5QA_tDkOd2m6yTeezEjPnJUsKXmzqh_-xg5bKKyRoYcLPhc12oLcNllbqYk93frao2PZoMx2sORUx_4pcYz9RwEXr81imuWXf7SNyh9SDQpMFBFidAngH-2aCSHCiL8Xf-KPw3QMC_ghENbDPKI9eGmwajWricNmOcM86Og/file\nResolving uca736102615a2cb98cdf01cbff1.dl.dropboxusercontent.com (uca736102615a2cb98cdf01cbff1.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6021:15::a27d:410f\nConnecting to uca736102615a2cb98cdf01cbff1.dl.dropboxusercontent.com (uca736102615a2cb98cdf01cbff1.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 638359 (623K) [text/plain]\nSaving to: ‘covid_test.csv’\n\ncovid_test.csv      100%[===================>] 623.40K  --.-KB/s    in 0.02s   \n\n2023-06-15 16:04:25 (32.8 MB/s) - ‘covid_test.csv’ saved [638359/638359]\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import packages","metadata":{"id":"igqIMEgu64-F"}},{"cell_type":"code","source":"# Numerical Operations\nimport math\nimport numpy as np\n\n# Reading/Writing Data\nimport pandas as pd\nimport os\nimport csv\n\n# For Progress Bar\nfrom tqdm import tqdm\n\n# Pytorch\nimport torch \nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\n# For plotting learning curve\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"id":"xybQNYCXYu13","execution":{"iopub.status.busy":"2023-06-15T16:04:25.999854Z","iopub.execute_input":"2023-06-15T16:04:26.000249Z","iopub.status.idle":"2023-06-15T16:04:26.007838Z","shell.execute_reply.started":"2023-06-15T16:04:26.000210Z","shell.execute_reply":"2023-06-15T16:04:26.006644Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"markdown","source":"# Some Utility Functions\n\nYou do not need to modify this part.","metadata":{"id":"fTAVqRfc2KK3"}},{"cell_type":"code","source":"# 设置随机种子，以确保实验的可重复性\ndef same_seed(seed): \n    '''Fixes random number generator seeds for reproducibility.'''\n    # 设置了PyTorch的CuDNN后端以确定性模式运行，这意味着所有的操作都将是确定的，即每次运行程序时，结果都将是相同的。\n    torch.backends.cudnn.deterministic = True\n    # 禁用了CuDNN的基准测试模式，这个模式通常用于加速训练，但在这里被禁用，以确保结果的一致性。\n    torch.backends.cudnn.benchmark = False\n    # 设置随机种子\n    np.random.seed(seed)\n    # 为CPU设置种子用于生成随机数，以使得结果是确定的\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        # 为当前GPU设置随机种子\n        torch.cuda.manual_seed_all(seed)\n# 将训练数据分为训练集和验证集\ndef train_valid_split(data_set, valid_ratio, seed):\n    '''Split provided training data into training set and validation set'''\n    # 计算了验证集的大小\n    valid_set_size = int(valid_ratio * len(data_set)) \n    # 计算了训练集的大小\n    train_set_size = len(data_set) - valid_set_size\n    # 使用PyTorch提供的random_split函数将数据集分割成训练集和验证集\n    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n    return np.array(train_set), np.array(valid_set)\n# 返回预测结果\ndef predict(test_loader, model, device):\n    model.eval() # Set your model to evaluation mode.\n    preds = []\n    # tqdm是一个快速，可扩展的Python进度条，可以在Python长循环中添加一个进度提示信息，用户只需要封装任意的迭代器tqdm(iterator)即可\n    for x in tqdm(test_loader):\n        # 将数据复制到指定的设备上\n        x = x.to(device)\n        # 禁用梯度计算\n        with torch.no_grad():\n            # 使用模型对输入数据x进行预测\n            pred = model(x)\n            # 将预测结果从设备上移除并转移到CPU上，然后添加到预测结果列表中\n            preds.append(pred.detach().cpu())\n    # 将预测结果拼接成一个numpy数组\n    preds = torch.cat(preds, dim=0).numpy()  \n    return preds","metadata":{"id":"RbrcpfYN2I-H","execution":{"iopub.status.busy":"2023-06-15T16:04:26.012744Z","iopub.execute_input":"2023-06-15T16:04:26.013117Z","iopub.status.idle":"2023-06-15T16:04:26.027112Z","shell.execute_reply.started":"2023-06-15T16:04:26.013080Z","shell.execute_reply":"2023-06-15T16:04:26.026058Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"IqO3lTm78nNO"}},{"cell_type":"code","source":"'''\n这段代码定义了一个名为COVID19Dataset的类,它继承自PyTorch的Dataset类。Dataset是一个抽象类,用于表示数据集,\n它要求所有子类实现__getitem__和__len__方法。\nCOVID19Dataset类用于表示COVID-19的数据集,包括特征(x)和目标(y)。\n'''\nclass COVID19Dataset(Dataset):\n    '''\n    x: Features.\n    y: Targets, if none, do prediction.\n    '''\n    def __init__(self, x, y=None):\n        if y is None:\n            self.y = y\n        else:\n            self.y = torch.FloatTensor(y)\n        self.x = torch.FloatTensor(x)\n\n    def __getitem__(self, idx):\n        if self.y is None:\n            return self.x[idx]\n        else:\n            return self.x[idx], self.y[idx]\n\n    def __len__(self):\n        return len(self.x)","metadata":{"id":"-mjaJM0wprMs","execution":{"iopub.status.busy":"2023-06-15T16:04:26.030477Z","iopub.execute_input":"2023-06-15T16:04:26.030813Z","iopub.status.idle":"2023-06-15T16:04:26.044482Z","shell.execute_reply.started":"2023-06-15T16:04:26.030782Z","shell.execute_reply":"2023-06-15T16:04:26.043384Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"markdown","source":"# Neural Network Model\nTry out different model architectures by modifying the class below.","metadata":{"id":"m73ooU75CL_j"}},{"cell_type":"code","source":"class My_Model(nn.Module):\n    def __init__(self, input_dim):\n        super(My_Model, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(input_dim, 64),\n            nn.ReLU(),\n            nn.Linear(64, 32),\n            nn.ReLU(),\n            nn.Linear(32, 16),\n            nn.ReLU(),\n            nn.Linear(16, 1)\n        )\n\n    # 定义了模型的前向传播过程。它接收一个输入x，然后通过self.layers进行处理，最后使用squeeze方法移除大小为1的维度\n    def forward(self, x):\n        x = self.layers(x)\n        x = x.squeeze(1) # (B, 1) -> (B)\n        return x","metadata":{"id":"Qn97_WvvrEkG","execution":{"iopub.status.busy":"2023-06-15T16:04:26.046773Z","iopub.execute_input":"2023-06-15T16:04:26.047110Z","iopub.status.idle":"2023-06-15T16:04:26.057454Z","shell.execute_reply.started":"2023-06-15T16:04:26.047083Z","shell.execute_reply":"2023-06-15T16:04:26.056388Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"markdown","source":"# Feature Selection\nChoose features you deem useful by modifying the function below.","metadata":{"id":"x5-LKF6R8xeq"}},{"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\n\ndef select_feat(train_data, valid_data, test_data, select_all, k):\n    '''Selects useful features to perform regression'''\n    # Extract target variables from training and validation data.\n    y_train, y_valid = train_data[:,-1], valid_data[:,-1]\n    # Extract feature variables from training, validation and test data.\n    raw_x_train, raw_x_valid, raw_x_test = train_data[:,:-1], valid_data[:,:-1], test_data\n\n    if select_all:\n        feat_idx = list(range(raw_x_train.shape[1]))\n    else:\n        # Create a Linear Regression model\n        model = LinearRegression()\n        # Create an RFE object\n        rfe = RFE(estimator=model, n_features_to_select=k)\n        # Fit the RFE object to the training data\n        rfe.fit(raw_x_train, y_train)\n        # Get the selected feature indices\n        feat_idx = [i for i in range(len(rfe.support_)) if rfe.support_[i]]\n\n    # Return selected feature variables and target variables\n    return raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid\n","metadata":{"id":"0FEnKRaIIeKp","execution":{"iopub.status.busy":"2023-06-15T16:04:26.059002Z","iopub.execute_input":"2023-06-15T16:04:26.059517Z","iopub.status.idle":"2023-06-15T16:04:26.070977Z","shell.execute_reply.started":"2023-06-15T16:04:26.059476Z","shell.execute_reply":"2023-06-15T16:04:26.069980Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"markdown","source":"# Training Loop","metadata":{"id":"kADIPNQ2Ih5X"}},{"cell_type":"code","source":"def trainer(train_loader, valid_loader, model, config, device):\n\n    criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n\n    # Define your optimization algorithm. \n    # TODO: Please check https://pytorch.org/docs/stable/optim.html to get more available algorithms.\n    # TODO: L2 regularization (optimizer(weight decay...) or implement by your self).\n    # 1.使用SGD优化器\n    # optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.7)\n    # 2.优化器使用Adam\n    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=0.01)\n    # 加入学习率衰减\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=800, gamma=0.1)  # 每100个epoch，学习率乘以0.1\n    # 3.优化器使用RMSprop\n    # optimizer = torch.optim.RMSprop(model.parameters(), lr=config['learning_rate'], weight_decay=0.01)\n    writer = SummaryWriter() # Writer of tensoboard.\n\n    if not os.path.isdir('./models'):\n        os.mkdir('./models') # Create directory of saving models.\n\n    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n\n    for epoch in range(n_epochs):\n        model.train() # Set your model to train mode.\n        loss_record = []\n\n        # tqdm is a package to visualize your training progress.\n        # train_pbar = tqdm(train_loader, position=0, leave=True)\n\n        for x, y in train_loader:\n            optimizer.zero_grad()               # Set gradient to zero.\n            x, y = x.to(device), y.to(device)   # Move your data to device. \n            pred = model(x)\n            loss = criterion(pred, y)\n            loss.backward()                     # Compute gradient(backpropagation).\n            optimizer.step()                    # Update parameters.\n            step += 1\n            loss_record.append(loss.detach().item())\n            \n            # Display current epoch number and loss on tqdm progress bar.\n            # train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n            # train_pbar.set_postfix({'loss': loss.detach().item()})\n\n        mean_train_loss = sum(loss_record)/len(loss_record)\n        writer.add_scalar('Loss/train', mean_train_loss, step)\n        scheduler.step()  # 更新学习率\n\n        model.eval() # Set your model to evaluation mode.\n        loss_record = []\n        for x, y in valid_loader:\n            x, y = x.to(device), y.to(device)\n            with torch.no_grad():\n                pred = model(x)\n                loss = criterion(pred, y)\n\n            loss_record.append(loss.item())\n            \n        mean_valid_loss = sum(loss_record)/len(loss_record)\n        # print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n        writer.add_scalar('Loss/valid', mean_valid_loss, step)\n\n        if mean_valid_loss < best_loss:\n            best_loss = mean_valid_loss\n            torch.save(model.state_dict(), config['save_path']) # Save your best model\n            print('Saving model with loss {:.3f}...'.format(best_loss))\n            early_stop_count = 0\n        else: \n            early_stop_count += 1\n\n        if early_stop_count >= config['early_stop']:\n            print('\\nModel is not improving, so we halt the training session.')\n            return","metadata":{"id":"k4Rq8_TztAhq","execution":{"iopub.status.busy":"2023-06-15T16:04:26.072499Z","iopub.execute_input":"2023-06-15T16:04:26.073157Z","iopub.status.idle":"2023-06-15T16:04:26.091624Z","shell.execute_reply.started":"2023-06-15T16:04:26.073077Z","shell.execute_reply":"2023-06-15T16:04:26.090663Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"markdown","source":"# Configurations\n`config` contains hyper-parameters for training and the path to save your model.","metadata":{"id":"0pgkOh2e9UjE"}},{"cell_type":"code","source":"device = 'cuda'\nconfig = {\n    'seed': 7,      # Your seed number, you can pick your lucky number. :)\n    'select_all': False,   # Whether to use all features.\n    'valid_ratio': 0.1,   # validation_size = train_size * valid_ratio\n    'n_epochs': 10000,     # Number of epochs.            \n    'batch_size': 512, \n    'learning_rate': 1e-3,              \n    'early_stop': 1000,    # If model has not improved for this many consecutive epochs, stop training.     \n    'save_path': './models/model.ckpt',  # Your model will be saved here.\n    'n_features_to_select': 20              # Number of selected features.\n}","metadata":{"id":"QoWPUahCtoT6","execution":{"iopub.status.busy":"2023-06-15T16:04:26.094545Z","iopub.execute_input":"2023-06-15T16:04:26.094963Z","iopub.status.idle":"2023-06-15T16:04:26.109886Z","shell.execute_reply.started":"2023-06-15T16:04:26.094928Z","shell.execute_reply":"2023-06-15T16:04:26.108895Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader\nRead data from files and set up training, validation, and testing sets. You do not need to modify this part.","metadata":{"id":"lrS-aJJh9XkW"}},{"cell_type":"code","source":"# Set seed for reproducibility\nsame_seed(config['seed'])\n\n\n# train_data size: 3009 x 89 (35 states + 18 features x 3 days) \n# test_data size: 997 x 88 (without last day's positive rate)\ntrain_data, test_data = pd.read_csv('./covid_train.csv').values, pd.read_csv('./covid_test.csv').values\ntrain_data, valid_data = train_valid_split(train_data, config['valid_ratio'], config['seed'])\n\n# Print out the data size.\nprint(f\"\"\"train_data size: {train_data.shape} \nvalid_data size: {valid_data.shape} \ntest_data size: {test_data.shape}\"\"\")\n\n# Select features\nx_train, x_valid, x_test, y_train, y_valid = select_feat(train_data, valid_data, test_data, config['select_all'], config['n_features_to_select'])\n\n# Print out the number of features.\nprint(f'number of features: {x_train.shape[1]}')\n\ntrain_dataset, valid_dataset, test_dataset = COVID19Dataset(x_train, y_train), \\\n                                            COVID19Dataset(x_valid, y_valid), \\\n                                            COVID19Dataset(x_test)\n\n# Pytorch data loader loads pytorch dataset into batches.\ntrain_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)","metadata":{"id":"2jc7ZfDot2t9","execution":{"iopub.status.busy":"2023-06-15T16:04:26.113578Z","iopub.execute_input":"2023-06-15T16:04:26.114271Z","iopub.status.idle":"2023-06-15T16:04:26.548335Z","shell.execute_reply.started":"2023-06-15T16:04:26.114235Z","shell.execute_reply":"2023-06-15T16:04:26.547125Z"},"trusted":true},"execution_count":122,"outputs":[{"name":"stdout","text":"train_data size: (2709, 89) \nvalid_data size: (300, 89) \ntest_data size: (997, 88)\nnumber of features: 20\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Start training!","metadata":{"id":"0OBYgjCA-YwD"}},{"cell_type":"code","source":"model = My_Model(input_dim=x_train.shape[1]).to(device) # put your model and data on the same computation device.\ntrainer(train_loader, valid_loader, model, config, device)","metadata":{"id":"YdttVRkAfu2t","execution":{"iopub.status.busy":"2023-06-15T16:04:26.549841Z","iopub.execute_input":"2023-06-15T16:04:26.550310Z","iopub.status.idle":"2023-06-15T16:05:24.355702Z","shell.execute_reply.started":"2023-06-15T16:04:26.550269Z","shell.execute_reply":"2023-06-15T16:05:24.354501Z"},"trusted":true},"execution_count":123,"outputs":[{"name":"stdout","text":"Saving model with loss 369.260...\nSaving model with loss 344.862...\nSaving model with loss 315.864...\nSaving model with loss 274.671...\nSaving model with loss 220.806...\nSaving model with loss 153.369...\nSaving model with loss 79.295...\nSaving model with loss 23.516...\nSaving model with loss 15.326...\nSaving model with loss 12.061...\nSaving model with loss 11.679...\nSaving model with loss 11.381...\nSaving model with loss 10.908...\nSaving model with loss 10.554...\nSaving model with loss 10.295...\nSaving model with loss 10.011...\nSaving model with loss 9.707...\nSaving model with loss 9.300...\nSaving model with loss 8.824...\nSaving model with loss 8.266...\nSaving model with loss 7.610...\nSaving model with loss 6.961...\nSaving model with loss 6.224...\nSaving model with loss 5.450...\nSaving model with loss 4.666...\nSaving model with loss 3.878...\nSaving model with loss 3.121...\nSaving model with loss 2.509...\nSaving model with loss 1.934...\nSaving model with loss 1.529...\nSaving model with loss 1.369...\nSaving model with loss 1.108...\nSaving model with loss 1.023...\nSaving model with loss 0.993...\nSaving model with loss 0.966...\nSaving model with loss 0.949...\nSaving model with loss 0.945...\nSaving model with loss 0.936...\nSaving model with loss 0.936...\nSaving model with loss 0.921...\nSaving model with loss 0.917...\nSaving model with loss 0.916...\nSaving model with loss 0.903...\nSaving model with loss 0.899...\nSaving model with loss 0.893...\nSaving model with loss 0.891...\nSaving model with loss 0.882...\nSaving model with loss 0.881...\nSaving model with loss 0.877...\nSaving model with loss 0.876...\nSaving model with loss 0.872...\nSaving model with loss 0.872...\nSaving model with loss 0.868...\nSaving model with loss 0.865...\nSaving model with loss 0.864...\nSaving model with loss 0.861...\nSaving model with loss 0.859...\nSaving model with loss 0.859...\nSaving model with loss 0.854...\nSaving model with loss 0.853...\nSaving model with loss 0.850...\nSaving model with loss 0.847...\nSaving model with loss 0.846...\nSaving model with loss 0.845...\nSaving model with loss 0.844...\nSaving model with loss 0.844...\nSaving model with loss 0.842...\nSaving model with loss 0.842...\nSaving model with loss 0.841...\nSaving model with loss 0.840...\nSaving model with loss 0.839...\nSaving model with loss 0.837...\nSaving model with loss 0.837...\nSaving model with loss 0.836...\nSaving model with loss 0.834...\nSaving model with loss 0.833...\nSaving model with loss 0.832...\nSaving model with loss 0.831...\nSaving model with loss 0.830...\nSaving model with loss 0.830...\nSaving model with loss 0.829...\nSaving model with loss 0.828...\nSaving model with loss 0.826...\nSaving model with loss 0.825...\nSaving model with loss 0.824...\nSaving model with loss 0.824...\nSaving model with loss 0.824...\nSaving model with loss 0.823...\nSaving model with loss 0.823...\nSaving model with loss 0.822...\nSaving model with loss 0.822...\nSaving model with loss 0.821...\nSaving model with loss 0.820...\nSaving model with loss 0.820...\nSaving model with loss 0.818...\nSaving model with loss 0.818...\nSaving model with loss 0.818...\nSaving model with loss 0.818...\nSaving model with loss 0.817...\nSaving model with loss 0.817...\nSaving model with loss 0.816...\nSaving model with loss 0.816...\nSaving model with loss 0.816...\nSaving model with loss 0.816...\nSaving model with loss 0.816...\nSaving model with loss 0.815...\nSaving model with loss 0.814...\nSaving model with loss 0.814...\nSaving model with loss 0.814...\nSaving model with loss 0.813...\n\nModel is not improving, so we halt the training session.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Testing\nThe predictions of your model on testing set will be stored at `pred.csv`.","metadata":{"id":"yhAHGqC9-woK"}},{"cell_type":"code","source":"def save_pred(preds, file):\n    ''' Save predictions to specified file '''\n    with open(file, 'w') as fp:\n        writer = csv.writer(fp)\n        writer.writerow(['id', 'tested_positive'])\n        for i, p in enumerate(preds):\n            writer.writerow([i, p])\n\nmodel = My_Model(input_dim=x_train.shape[1]).to(device)\nmodel.load_state_dict(torch.load(config['save_path']))\npreds = predict(test_loader, model, device) \nsave_pred(preds, 'pred.csv')         ","metadata":{"id":"Q5eVdpbvAlAe","execution":{"iopub.status.busy":"2023-06-15T16:05:24.357451Z","iopub.execute_input":"2023-06-15T16:05:24.358327Z","iopub.status.idle":"2023-06-15T16:05:24.384774Z","shell.execute_reply.started":"2023-06-15T16:05:24.358280Z","shell.execute_reply":"2023-06-15T16:05:24.383562Z"},"trusted":true},"execution_count":124,"outputs":[{"name":"stderr","text":"100%|██████████| 2/2 [00:00<00:00, 342.78it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Download\n\nRun this block to download the `pred.csv` by clicking.","metadata":{"id":"T_N-wBvVahc7"}},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'pred.csv')","metadata":{"id":"PmMnwrHeavJv","execution":{"iopub.status.busy":"2023-06-15T16:05:24.386604Z","iopub.execute_input":"2023-06-15T16:05:24.387066Z","iopub.status.idle":"2023-06-15T16:05:24.398237Z","shell.execute_reply.started":"2023-06-15T16:05:24.387022Z","shell.execute_reply":"2023-06-15T16:05:24.396991Z"},"trusted":true},"execution_count":125,"outputs":[{"execution_count":125,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/pred.csv","text/html":"<a href='pred.csv' target='_blank'>pred.csv</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Reference\nThis notebook uses code written by Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)","metadata":{"id":"IJ_k5rY0GvSV"}}]}